plot_model(logit.3,
type="pred",
terms = "rural_urban",
title="Predicted Probability of the Trump majority vote",
axis.title = c(" ","Predicted probability"))
Rural.Urban.Table <- Counties %>%
group_by(rural_urban)%>%
summarize(n=n())%>%
mutate(prop=round(n/sum(n),4))   # our new proportion variable, rounded
Rural.Urban.Table
ggplot(Counties, aes(x=factor(rural_urban))) +
geom_bar(aes(y=..prop.., group=1), color="blue", fill="blue") +
labs(title="USDA Urban/Rural Status of US Counties in 2016", x=NULL, y="Proportion") +
scale_x_discrete(labels = c("1 Million","250,000 to 1 million","< 250,000", "20k+ near metro area", "20k+ not near  metro area", "2,500-19,999 near metro area", "2,500-19,999 not near metro area", "< 2,500 near metro area", "< 2,500 not near metro area", "NA")) +
scale_y_continuous(limits=c(0,.25)) +
coord_flip()
ANES <- read.csv("ANES_8004.csv")
names(ANES)
dim(ANES)
# Convert selected variables into factor variables
ANES$enthusiasmDf <- factor(ANES$enthusiasmD, labels=c("Not proud and hopeful","Proud and hopeful"))
ANES$enthusiasmRf <- factor(ANES$enthusiasmR, labels=c("Not proud and hopeful","Proud and hopeful"))
ANES$angryDf <- factor(ANES$angryD, labels=c("Not angry","angry"))
ANES$angryRf <- factor(ANES$angryR, labels=c("Not angry","angry"))
ANES$afraidDf <- factor(ANES$afraidD, labels=c("Not afraid","afraid"))
ANES$afraidRf <- factor(ANES$afraidR, labels=c("Not afraid","afraid"))
ANES$pid[ANES$pid==0]<-"Neither"
ANES$pid[ANES$pid==1]<-"Democrat"
ANES$pid[ANES$pid==2]<-"Republican"
ANES$partyf <- factor(ANES$pid, levels = c("Neither", "Democrat", "Republican"))
ANES$femalef <- factor(ANES$female, labels=c("Male","Female"))
ANES$blackf <- factor(ANES$black, labels=c("Non-Black","Black"))
ANES$hispanicf <- factor(ANES$hispanic, labels=c("Non-Hispanic","Hispanic"))
library(ggplot2)
ggplot(ANES, aes(x=enthusiasmRf, y=turnout)) +
geom_bar(stat="identity", width=0.5) +
scale_x_discrete(na.translate = FALSE)+
labs(title="Number of Voter Turnout \n by Positive feelings towards a Republican candidate",
y="Number of Voter Turnout",
x="Positive Feelings towards a Republican Candidate")
library(dplyr)
ggplot(ANES, aes(x=!is.na(enthusiasmRf), fill=factor(turnout))) +
geom_bar(position="dodge",aes(y=..prop.., group=factor(turnout))) +
scale_x_discrete(labels=c("Not proud and hopeful", "Proud and hopeful")) +
scale_fill_discrete(name="Turnout Decision", labels=c("Did not vote", "Voted")) +
labs(title="Proportion of Turnout \n by Positive feelings towards a Republican candidate",
y="Turnout Rate",
x="")
library(dplyr)
ggplot(ANES, aes(x=enthusiasmRf, fill=factor(turnout))) +
geom_bar(position="dodge",aes(y=..prop.., group=factor(turnout))) +
scale_x_discrete(labels=c("Not proud and hopeful", "Proud and hopeful")) +
scale_fill_discrete(name="Turnout Decision", labels=c("Did not vote", "Voted")) +
labs(title="Proportion of Turnout \n by Positive feelings towards a Republican candidate",
y="Turnout Rate",
x="")
library(dplyr)
ggplot(ANES, aes(x=!isn.a(enthusiasmRf), fill=factor(turnout))) +
geom_bar(position="dodge",aes(y=..prop.., group=factor(turnout))) +
scale_x_discrete(labels=c("Not proud and hopeful", "Proud and hopeful")) +
scale_fill_discrete(name="Turnout Decision", labels=c("Did not vote", "Voted")) +
labs(title="Proportion of Turnout \n by Positive feelings towards a Republican candidate",
y="Turnout Rate",
x="")
library(dplyr)
ggplot(ANES, aes(x=!is.na(enthusiasmRf), fill=factor(turnout))) +
geom_bar(position="dodge",aes(y=..prop.., group=factor(turnout))) +
scale_x_discrete(labels=c("Not proud and hopeful", "Proud and hopeful")) +
scale_fill_discrete(name="Turnout Decision", labels=c("Did not vote", "Voted")) +
labs(title="Proportion of Turnout \n by Positive feelings towards a Republican candidate",
y="Turnout Rate",
x="")
library(RCurl)
data<-getURL(https://github.com/tomogradyucl/Causal-Inference-for-Beginning-Undergraduates/blob/master/Weekly%20R%20Assignments%20-%20Datasets/benin.Rda)
data<-getURL("https://github.com/tomogradyucl/Causal-Inference-for-Beginning-Undergraduates/blob/master/Weekly%20R%20Assignments%20-%20Datasets/benin.Rda")
data<-getURL("https://github.com/tomogradyucl/Causal-Inference-for-Beginning-Undergraduates/blob/master/Weekly%20R%20Assignments%20-%20Datasets/benin.Rda",ssl.verifypeer = FALSE)
data<-getURL("https://github.com/tomogradyucl/Causal-Inference-for-Beginning-Undergraduates/blob/master/Weekly%20R%20Assignments%20-%20Datasets/benin.Rda",ssl.verifypeer = TRUE)
url<-https://github.com/tomogradyucl/Causal-Inference-for-Beginning-Undergraduates/blob/master/Weekly%20R%20Assignments%20-%20Datasets/benin.Rda
url<-"https://github.com/tomogradyucl/Causal-Inference-for-Beginning-Undergraduates/blob/master/Weekly%20R%20Assignments%20-%20Datasets/benin.Rda"
load(url(url))
git<-"https://github.com/tomogradyucl/Causal-Inference-for-Beginning-Undergraduates/blob/master/Weekly%20R%20Assignments%20-%20Datasets/benin.Rda"
load(url(git))
library(readr)
read_rds(url(git))
download.file(git,"benin")
load(benin)
load("benin")
read_rds("benin")
readRDS("benin")
readRDS("benin.rds")
readRDS("benin.rda")
read_rds("benin.rda")
download.file(git,"benin.Rda")
data<-readRDS("benin.Rda")
getwd()
data<-load("benin.Rda")
data<-read_rds("benin.Rda")
data<-read_rds("\benin.Rda")
download.file(git,"test.Rda")
data<-read_rds("\test.Rda")
file.exists("benin.Rda")
filename <- file.choose("benin")
test <- readRDS("benin")
test <- readRDS("benin.Rda")
test <- readRDS("benin.rda")
getwd()
test <- readRDS("C:/Users/joerh/Documents/benin.rda")
test <- readRDS("C:\Users\joerh/Documents\benin.Rda")
test <- readRDS("C:/Users/joerh/Documents/benin.Rda")
test <- readRDS("C:/Users/joerh/Documents/benin.rda")
library(tidyverse)
test <- readRDS("C:/Users/joerh/Documents/benin.rda")
filename <- file.choose("benin")
test <- readRDS(filename)
download.file(git,"benin.RData")
load("benin.RData")
readRDS("benin.RData")
load("~/benin.RData")
load("~/benin.Rda")
download.file(git,"benin.Rda")
load("~/benin.Rda")
saveRDS(git,"benin.Rda")
readRDS("benin.Rda")
download.file(git,"benin.Rda",version=2)
load("~/benin.Rda")
load(url(git)
)
x <- RCurl::getURL(git)
readr::read_rds("benin.Rda")
save(benin, file=git)
devtools::use_data(benin, internal = TRUE)
load(url(git))
getwd()
git
setwd("C:/Users/joerh/Documents")
working_directory <- getwd()
if (!file.exists("benin.Rda")) {
download.file(   "https://github.com/tomogradyucl/Causal-Inference-for-Beginning-Undergraduates/blob/master/Weekly%20R%20Assignments%20-%20Datasets/benin.Rda",   "PakPMICS2018bhURL.RData")
load(file.path(working_directory, "benin.Rda"))
}
setwd("C:/Users/joerh/Documents")
working_directory <- getwd()
if (!file.exists("benin.Rda")) {
download.file(   "https://github.com/tomogradyucl/Causal-Inference-for-Beginning-Undergraduates/blob/master/Weekly%20R%20Assignments%20-%20Datasets/benin.Rda",   "benin.RData")
load(file.path(working_directory, "benin.Rda"))
}
rm(list=ls())
setwd("C:/Users/joerh/Documents")
working_directory <- getwd()
if (!file.exists("benin.Rda")) {
download.file(   "https://github.com/tomogradyucl/Causal-Inference-for-Beginning-Undergraduates/blob/master/Weekly%20R%20Assignments%20-%20Datasets/benin.Rda",   "benin.RData")
load(file.path(working_directory, "benin.Rda"))
}
readRDS(url("https://github.com/tomogradyucl/Causal-Inference-for-Beginning-Undergraduates/blob/master/Weekly%20R%20Assignments%20-%20Datasets/benin.Rda"))
load(file.path(working_directory, "benin.Rda")
)
load(file.path(working_directory, "benin.Rda"),version=2)
?load
readRDS(file.path(working_directory, "benin.Rda"), version=2)
load("~/benin.Rda")
load("~/benin.Rda")
getwd()
load("benin.Rda")
write.csv(b,"benin.csv")
View(b)
git<-"https://github.com/tomogradyucl/Causal-Inference-for-Beginning-Undergraduates/blob/master/Weekly%20R%20Assignments%20-%20Datasets/benin.Rda"
download.file(git,"benin.csv")
load("benin.csv")
readRDS(url(git))
readRDS(git
)
setwd("C:/Users/joerh/Documents")
working_directory <- getwd()
if (!file.exists("benin.Rda")) {
download.file("https://github.com/tomogradyucl/Causal-Inference-for-Beginning-Undergraduates/blob/master/Weekly%20R%20Assignments%20-%20Datasets/benin.Rda","benin.Rda")
load(file.path(working_directory, "benin.Rda"))
}
t<-source("benin.rda")
t<-source("benin.Rda")
source("benin.Rda")
read.csv("benin.Rda")
t<-read.csv("benin.Rda")
View(t)
t<-readRDS("benin.Rda")
t<-readRDS("benin.rda")
t<-readRDS("benin.rds")
devtools::use_data(git, internal = TRUE)
install.packages("processx")
library(processx)
devtools::use_data(git, internal = TRUE)
loac("~/benin.Rda")
load("~/benin.Rda")
source("benin.Rda")
source("benin.Rda")
load("benin.Rda")
?download.file
download.file(git,"benin.Rda",method="curl")
t<-load("~/benin.Rda")
load(url("https://github.com/tomogradyucl/Causal-Inference-for-Beginning-Undergraduates/blob/master/Weekly%20R%20Assignments%20-%20Datasets/experiment.Rda"))
library(RCurl)
library(repmis)
source_data("https://github.com/tomogradyucl/Causal-Inference-for-Beginning-Undergraduates/blob/master/Weekly%20R%20Assignments%20-%20Datasets/experiment.Rda")
install.packages("repmis")
source_data("https://github.com/tomogradyucl/Causal-Inference-for-Beginning-Undergraduates/blob/master/Weekly%20R%20Assignments%20-%20Datasets/experiment.Rda?raw=true")
library(repmis)
source_data("https://github.com/tomogradyucl/Causal-Inference-for-Beginning-Undergraduates/blob/master/Weekly%20R%20Assignments%20-%20Datasets/experiment.Rda?raw=true")
View(a)
source_data("https://github.com/tomogradyucl/Causal-Inference-for-Beginning-Undergraduates/blob/master/Weekly%20R%20Assignments%20-%20Datasets/benin.Rda?raw=true")
View(b)
source_data("https://github.com/tomogradyucl/Causal-Inference-for-Beginning-Undergraduates/blob/master/Weekly%20R%20Assignments%20-%20Datasets/t4data.Rda?raw=true")
load("C:/Users/joerh/Dropbox/2.PSUgrad/14) My Projects/(9) Other ideas/Climate migration/Data/netlm_ols_result_3way_comm.RData")
View(coef)
# Directory
#setwd("C:/Users/boyoo/Dropbox/2.PSUgrad/14) My Projects/(9) Other ideas/Climate migration/")
setwd("C:/Users/joerh/Dropbox/2.PSUgrad/14) My Projects/(9) Other ideas/Climate migration/")
library(tidyverse)
library(tidyr)
library(dplyr)
library(zoo) # For Intrapolation
years <- 2008:2018
# empty list object in which to store data
migrationList <- list()
# loop over years
for(i in 1:length(years)){
# name of migration file on disc
migrationFile <- paste("Data/irs_migration/send_migration",years[i],".csv",sep="")
# store as data frame
migrationList[[i]] <- read.csv(migrationFile,stringsAsFactors=F)
}
names(migrationList) <- years
# Add year variable
for(i in 1:length(migrationList)){
migrationList[[i]]$Year <- as.numeric(names(migrationList)[[i]])
names(migrationList[[i]])[2]<-"household_flow"
names(migrationList[[i]])[3]<-"ind_flow"
}
# Append each list object
migflow<-as.data.frame(migrationList[[1]])
# loop over years to combine
for(t in 2:length(migrationList)){
nextyr<-as.data.frame(migrationList[[t]])
migflow<- rbind(migflow,nextyr)
}
migflow<-migflow[order(migflow$sender_fips,migflow$Year),]
# Top 5 damages
cov0918<-read.csv("Data/cov0918.csv")
View(cov0918)
colnames(cov0918)
cov0918<-cov0918[with(cov0918,order(-all_PropDmg)),]
range(cov0918$med_income)
summary(cov0918$med_income)
comparison<-cov0918[,c(1:4,8,14:15,41:42,71)]
View(comparison)
summary(comparison)
tx2017<-subset(comparison$state_code==48&comparison$Year==2017)
tx2017<-subset(comparison,comparison$state_code==48&comparison$Year==2017)
View(tx2017)
tx2017$countyname<-c("Harris","Galveston","Fort Bend","Montgomery","Brazoria","Jefferson","Aransas","Orange","Nueces","Walker","Liberty","San Jacinto","Polk","Hardin","San Patricio","Matagorda","Waller","Calhoun","Ector","Wharton","Victoria","Washington","Jasper","Tyler","Fayette","Grimes","Caldwell","Webb","Brazos")
tx<-read.csv("Data/CENSUS_fips/coounty_tx.csv")
tx<-read.csv("Data/CENSUS_fips/county_tx.csv")
TX<-merge(tx2017,tx,by="fips_code")
View(TX)
TX<-TX[with(TX,order(-all_PropDmg))]
TX<-TX[with(TX,order(-all_PropDmg)),]
View(comparison)
# CA county (2018) Wildfire
ca2018<-subset(comparison,comparison$state_code==6&comparison$Year==2018)
ca<-read.csv("Data/CENSUS_fips/county_ca.csv")
CA<-merge(ca2018,ca,by="fips_code")
CA<-CA[with(CA,order(-all_PropDmg)),]
View(CA)
View(migflow)
fips<-subset(comparison,comparison$Year==2015)
View(fips)
YYYY<-2009
cov <- paste0("Data/covariates", YYYY, ".csv")
covariates <- read.csv(cov,stringsAsFactors=F)
# Log transformation on population
pop<-grep(pattern='population_',x=colnames(covariates))
covariates$population_log<-log(c(covariates[,pop])+1)
# Log transformation on median income
medinc<-grep(pattern='med_income_',x=colnames(covariates))
covariates$med_income_log<-log(covariates[,medinc]+1)
# Log transformation on Property Damage
property<-grep(pattern='PropDmg',x=colnames(covariates))[1:8]
property_log<-log(covariates[,property]+1)
colnames(property_log)<-paste0(colnames(property_log),"_log")
covariates<-cbind(covariates,property_log)
# Log transformation on injury and fatality
covariates$all_injury_log<-log(c(covariates$all_injury+1))
covariates$all_fatality_log<-log(c(covariates$all_fatality+1))
# Combine injury and fatality
covariates$personal_harm<-covariates$all_injury+covariates$all_fatality
covariates$personal_harm_log<-log(c(covariates$personal_harm+1))
# Race variables: make it run between 0 to 1
white<-grep(pattern='pct_white_',x=colnames(covariates))
covariates$pct_white<-c(covariates[,white])/100
black<-grep(pattern='pct_black_',x=colnames(covariates))
covariates$pct_black<-c(covariates[,black])/100
hisp<-grep(pattern='pct_hispanic_',x=colnames(covariates))
covariates$pct_hispanic<-c(covariates[,hisp])/100
# Create interaction variables: Sender income * Sender resilience
covariates$incomeXbric_comm<-covariates$med_income_log*covariates$comm_cap
covariates$incomeXbric_inst<-covariates$med_income_log*covariates$institutional
# Create interaction variables: Sender Property damage * Sender income
#climate<-grep(pattern = "_injury|_fatality|_PropDmg_log",x=colnames(covariates))[c(1:16,33:40)]
climate<-grep(pattern = "_PropDmg_log",x=colnames(covariates))
climate_income<-covariates[,climate]*covariates$med_income_log
colnames(climate_income)<-paste0(colnames(climate_income),"Xincome")
covariates<-cbind(covariates,climate_income)
# Create interaction variables: Sender Property damage * sender resilience
climate_bric_comm<-covariates[,climate]*covariates$comm_cap
colnames(climate_bric_comm)<-paste0(colnames(climate_bric_comm),"Xbric_comm")
climate_bric_inst<-covariates[,climate]*covariates$institutional
colnames(climate_bric_inst)<-paste0(colnames(climate_bric_inst),"Xbric_inst")
covariates<-cbind(covariates,climate_bric_comm,climate_bric_inst)
# Create interaction variables: Sender Property damage * sender income * sender resilience
climate_3way_bric_comm<-covariates[,climate]*covariates$comm_cap*covariates$med_income_log
colnames(climate_3way_bric_comm)<-paste0(colnames(climate_3way_bric_comm),"Xbric_commXincome")
climate_3way_bric_inst<-covariates[,climate]*covariates$institutional*covariates$med_income_log
colnames(climate_3way_bric_inst)<-paste0(colnames(climate_3way_bric_inst),"Xbric_instXincome")
covariates<-cbind(covariates,climate_3way_bric_comm,climate_3way_bric_inst)
# Remove duplicated rows (in 2016 and 2017)
covariates<-covariates[!duplicated(covariates$node_id),]
years <- 2000:2018
# empty list object in which to store data
migrationList <- list()
# loop over years
for(i in 1:length(years)){
# name of migration file on disc
migrationFile <- paste("Data/liu_andris_desmarais_2019_migration_and_political polarization/plosone_data/migflow",years[i],"_county_nodeid_dist.csv",sep="")
# store as data frame
migrationList[[i]] <- read.csv(migrationFile,stringsAsFactors=F)
}
names(migrationList) <- years
# create list of migration adjacency matrices
migrationMatrices <- list()
for(i in 1:length(migrationList)){
# create empty adjacency matrix
amat <- matrix(0,nrow(covariates),nrow(covariates))
# grab data from the respective year
migrationData <- migrationList[[i]]
# match sender county to key
senderid <- match(migrationData[,1],covariates[,3])
# match receiver county to key
receiverid <- match(migrationData[,2],covariates[,3])
# take out any counties that are not in the election data
missing_county <- which(is.na(senderid)+is.na(receiverid)>0)
if(length(missing_county)>0) migrationData <- migrationData[-missing_county,]
# store migration flows in the adjacency matrix
amat[as.matrix(migrationData[,c(1,2)])] <- migrationData$exemptions
# print state of loop to keep track of progress
#print(i); print(length(missing_county))
# store adjacency matrix
migrationMatrices[[i]] <- amat
}
# create a network for two years
# create empty adjacency matrix
amat <- matrix(0,nrow(covariates),nrow(covariates))
amat <- as.matrix(migrationMatrices[[(YYYY-1999)]])
# loop over years to combine
#for(t in (YYYY:(YYYY+1)-min(years)+1)){
# add the adjacency matrices
#amat <- amat + as.matrix(migrationMatrices[[t]])
#}
# Take the log for the flow
amat <- log(amat + 1)
net_2y <- network(amat)
# store election results data in the network object
set.vertex.attribute(net_2y,names(covariates),covariates)
# extract edge values (migration flows)
evals <- amat[as.matrix(net_2y,"edgelist")]
# set as edge attribute
set.edge.attribute(net_2y,"edgeValue",evals)
library(network)
library(ergm.count)
library(latentnet)
library(sna)
net_2y <- network(amat)
set.vertex.attribute(net_2y,names(election_results),election_results)
set.vertex.attribute(net_2y,names(covariates),covariates)
list.vertex.attributes(net_2y)
View(covariates)
evals <- amat[as.matrix(net_2y,"edgelist")]
# set as edge attribute
set.edge.attribute(net_2y,"edgeValue",evals)
evals
test<-get.edges(net_2y,"node_id",neighborhood = "out")
test<-get.edges(net_2y,node_id,neighborhood = "out")
test<-get.edges(net_2y,67,neighborhood = "out")
View(test)
test<-get.vertex.attribute(net_2y,"node_id")
View(amat)
amat[1,463]
amat[1,462]
amat[1,464]
amat[1,740]
amat[1,739]
amat[1,730:750]
amat[1,800:850]
View(covariates)
ID<-covariates[,c(3,2)]
View(migflow)
View(ID)
write.csv(ID,"Data/fips_order.csv")
View(ID)
ID<-covariates[,c(3,2,4)]
View(ID)
ID<-covariates[,c(3,2,4:5)]
ID<-ID[,-which(ID$state=="HI")]
table(ID$state)
ID<-ID[,-which(ID$state=='HI')]
ID<-ID[,-which(ID$state == 'HI')]
table(ID$state,ID$state_code)
ID<-ID[,-which(ID$state_code==15)]
ID<-ID[,!which(ID$state_code==15)]
ID<-covariates[,c(3,2,4:5)]
ID<-ID[-which(ID$state=="HI")]
ID<-ID[-which(ID$state=="HI"),]
write.csv(ID,"Data/fips_order.csv")
knit_with_parameters('C:/Users/joerh/Dropbox/2.PSUgrad/20) 2021 Fall/PLSC 498_Analysis of Political Economy/1_R installation and basics.Rmd', encoding = 'UTF-8')
if (!require('knitr')) {install.packages("knitr")}
if (!require('devtools')) {install.packages("devtools")}
if (!require('RWordPress')) {devtools::install_github(c("duncantl/XMLRPC", "duncantl/RWordPress"))}
library(knitr); library(RWordPress)
options(WordpressLogin = c(user = 'Qhdbs9508!'),
WordpressURL = 'http://boyoonlee.com/xmlrpc.php')
knit2wp('1_R installation and basics.RmD',
title = 'Getting started with R',
publish = FALSE,
action = "newPost")
library(RWordPress)
knit2wp('1_R installation and basics.RmD',
title = 'Getting started with R',
publish = FALSE,
action = "newPost")
library(knitr); library(RWordPress)
?options
options(WordpressLogin = c(boyoon0715@gmail.com = 'Qhdbs9508!'),
WordpressURL = 'https://boyoonlee.com/2021/08/29/plsc-498-analytical-political-economy')
options(WordpressLogin = c(boyoon0715 = 'Qhdbs9508!'),
WordpressURL = 'https://boyoonlee.com/2021/08/29/plsc-498-analytical-political-economy')
options(WordpressLogin = c(boyoon0715 = 'Qhdbs9508!'),
WordpressURL = 'https://boyoonlee.com/xmlrpc.php')
knit2wp('1_R installation and basics.RmD',
title = 'Getting started with R',
publish = FALSE,
action = "newPost")
knit2wp('C:/Users/joerh/git/R_Workshops/1_R installation and basics.RmD',
title = 'Getting started with R',
publish = FALSE,
action = "newPost")
options(WordpressLogin = c(username = 'Qhdbs9508!'),
WordpressURL = 'https://boyoonlee.com/xmlrpc.php')
knit2wp('C:/Users/joerh/git/R_Workshops/1_R installation and basics.RmD',
title = 'Getting started with R',
publish = FALSE,
action = "newPost")
knit2wp('C:/Users/joerh/git/R_Workshops/1_R installation and basics.RmD',
title = 'Getting started with R',
publish = FALSE,
action = "newPost")
options(WordpressLogin = c(boyoon0715 = 'Qhdbs9508!'),
WordpressURL = 'https://boyoonlee.com/xmlrpc.php')
knit2wp('C:/Users/joerh/git/R_Workshops/1_R installation and basics.RmD',
title = 'Getting started with R',
publish = FALSE,
action = "newPost")
knit2wp('C:/Users/joerh/git/R_Workshops/2_R Data structure.RmD',
title = 'Getting started with R',
publish = FALSE,
action = "newPost")
library(dplyr)
library(haven)
Counties2016 <- read_dta("C:/Users/joerh/Dropbox/2.PSUgrad/12) 2019 Fall/PLSC309 Quantitative Political Analysis/In-Class R notebooks/Counties2016.dta")
View(Counties2016)
Counties<-Counties2016
library(dplyr)
# Counties above the median value of the proportion of Hispanic resident is coded as 1, 0 if below the median.
Counties <- Counties %>%
mutate(hispanic = ifelse(prop_hispanic > median(prop_hispanic,na.rm=T), 1, 0))
# Make the hispanic variable into a factor variable.
Counties$hispanicF <- factor(Counties$hispanic, labels =  c("Below median", "Above median"))
knit_with_parameters('C:/Users/joerh/git/R_Workshops/4_Do Your Analysis in R.Rmd')
knit2wp('C:/Users/joerh/git/R_Workshops/4_Merge Data in R.RmD',
title = 'Data Structure in R',
publish = FALSE,
action = "newPost")
knit2wp('C:/Users/joerh/git/R_Workshops/4_Merge Data in R.RmD',
title = 'Data Structure in R',
publish = FALSE,
action = "newPost")
# Load dataset from GitHub
urlfile<-'https://github.com/boyoon0715/R_Workshops/blob/main/cleaned_ANES.csv'
ANES<-read.csv(url(urlfile))
View(ANES)
# Load dataset from GitHub
urlfile<-'https://raw.githubusercontent.com/boyoon0715/R_Workshops/main/cleaned_ANES.csv'
ANES<-read.csv(url(urlfile))
colnames(ANES)
urlfile<-'https://raw.githubusercontent.com/boyoon0715/R_Workshops/main/cleaned_ANES.csv'
ANES<-read.csv(url(urlfile))
# list the variable names
names(ANES)
knit2wp('C:/Users/joerh/git/R_Workshops/3_Data manipulation R.RmD',
title = 'Manipulate Data in R',
publish = FALSE,
action = "newPost")
knit2wp('C:/Users/joerh/git/R_Workshops/3_Data manipulation.RmD',
title = 'Manipulate Data in R',
publish = FALSE,
action = "newPost")
